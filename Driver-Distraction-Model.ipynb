{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\ddm\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\envs\\ddm\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\envs\\ddm\\lib\\site-packages (1.5.2)\n",
      "Collecting deap\n",
      "  Downloading deap-1.4.1-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading deap-1.4.1-cp39-cp39-win_amd64.whl (109 kB)\n",
      "Installing collected packages: deap\n",
      "Successfully installed deap-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn deap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp39-cp39-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.1/7.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.5/7.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Downloading pillow-11.0.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.55.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\anaconda\\envs\\ddm\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.1.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (3.17.2)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wheel>=0.35 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras>=2.4.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard~=2.6->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\anaconda\\envs\\ddm\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
      "Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "   ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/14.7 MB 13.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.8/14.7 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.7 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.7 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.7/14.7 MB 15.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.23.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from deap import base, creator, tools, algorithms\n",
    "from tensorflow.keras.backend import clear_session\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "Keras version: 2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "from random import shuffle, seed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, DenseNet121\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_44733.jpg', 'img_72999.jpg', 'img_25094.jpg', 'img_69092.jpg', 'img_92629.jpg']\n",
      "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "with open('SOPM/state-farm-distracted-driver-detection/driver_imgs_list.csv') as file:\n",
    "    read_file = csv.reader(file)\n",
    "    read_file = list(read_file)\n",
    "    \n",
    "    for row in read_file[1:]:\n",
    "        key = row[1]\n",
    "        if key in data:\n",
    "            data[key].append(row[2])\n",
    "        else:\n",
    "            data[key] = [row[2]]\n",
    "classes_list = list(data.keys())\n",
    "print(data['c0'][:5])\n",
    "print(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset :  22424\n",
      "Number of images in the testing dataset :  79726\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = 'SOPM/state-farm-distracted-driver-detection/imgs/'\n",
    "\n",
    "train_dir = os.path.join(dataset_folder, 'train_full/')\n",
    "test_dir = os.path.join(dataset_folder, 'test_full/')\n",
    "\n",
    "print('Number of images in the training dataset : ', str(len(glob(train_dir+'*/*'))))\n",
    "print('Number of images in the testing dataset : ', str(len(glob(test_dir+'*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOPM/state-farm-distracted-driver-detection/smallset\n",
      "Number of images for each class:  c0 -> 497\n",
      "Number of images for each class:  c1 -> 453\n",
      "Number of images for each class:  c2 -> 463\n",
      "Number of images for each class:  c3 -> 469\n",
      "Number of images for each class:  c4 -> 465\n",
      "Number of images for each class:  c5 -> 462\n",
      "Number of images for each class:  c6 -> 465\n",
      "Number of images for each class:  c7 -> 400\n",
      "Number of images for each class:  c8 -> 382\n",
      "Number of images for each class:  c9 -> 425\n"
     ]
    }
   ],
   "source": [
    "dataset_small_folder_path = 'SOPM/state-farm-distracted-driver-detection/smallset'\n",
    "subfolders = classes_list\n",
    "\n",
    "if os.path.exists(dataset_small_folder_path):\n",
    "    for root, dirs, files in os.walk(dataset_small_folder_path, topdown = False):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            os.remove(file_path)\n",
    "        for name in dirs:\n",
    "            dir_path = os.path.join(root, name)\n",
    "            os.rmdir(dir_path)\n",
    "    \n",
    "for folder in subfolders:\n",
    "            subfolder_path = os.path.join(dataset_small_folder_path, folder)\n",
    "            os.makedirs(subfolder_path)\n",
    "for clas, images in data.items():\n",
    "    length = len(images)\n",
    "    seed(42)\n",
    "    shuffle(images)\n",
    "    for image in images[:int(length*0.2)]:\n",
    "        source = os.path.join(dataset_folder, 'train_full/', clas, image)\n",
    "        #print(source)                     \n",
    "        destination = os.path.join(dataset_small_folder_path, clas, image)\n",
    "        copyfile(source, destination)\n",
    "        \n",
    "print(dataset_small_folder_path)\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(dataset_small_folder_path, subfolder)\n",
    "    print(\"Number of images for each class: \", subfolder, \"->\", len(os.listdir(subfolder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = {}\n",
    "for subfolder in os.listdir(dataset_small_folder_path):\n",
    "    small_dataset[subfolder] = os.listdir(os.path.join(dataset_small_folder_path, subfolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_directory(path):\n",
    "    for root, dirs, files in os.walk(path, topdown = False):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            os.remove(file_path)\n",
    "        for name in dirs:\n",
    "            dir_path = os.path.join(root, name)\n",
    "            os.rmdir(dir_path)\n",
    "    os.rmdir(path)\n",
    "\n",
    "def create_directories(paths, subfolders):\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            remove_directory(path)\n",
    "        \n",
    "        for folder in subfolders:\n",
    "            subfolder_path = os.path.join(path, folder)\n",
    "            os.makedirs(subfolder_path)\n",
    "\n",
    "paths = ['SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/train',\n",
    "         'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/val',\n",
    "        'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/test']\n",
    "subfolders = classes_list\n",
    "create_directories(paths, subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = [0.8, 0.1]\n",
    "\n",
    "\n",
    "for clas, images in small_dataset.items():\n",
    "    # print(len(images))\n",
    "    train_size = int(split_size[0]*len(images))\n",
    "    # print(\"Train size: \", train_size)\n",
    "    \n",
    "    test_size = int(split_size[1]*len(images))\n",
    "    #print(\"Test size: \", test_size)\n",
    "    \n",
    "    train_images = images[:train_size]\n",
    "    # print(\"Train Images Length\", len(train_images))\n",
    "    \n",
    "    val_images = images[train_size: train_size + test_size]\n",
    "    # print(\"Val Images Length\", len(val_images))\n",
    "    \n",
    "    test_images = images[train_size + test_size:]\n",
    "    \n",
    "    for image in train_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        # print(os.path.exists(source))\n",
    "        dest = os.path.join(paths[0], clas, image)\n",
    "        copyfile(source, dest)\n",
    "    \n",
    "    for image in val_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        dest = os.path.join(paths[1], clas, image)\n",
    "        copyfile(source, dest)\n",
    "    \n",
    "    for image in test_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        dest = os.path.join(paths[2], clas, image)\n",
    "        copyfile(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagedatageneration(train_dir, val_dir, test_dir, target_size = (256, 256), batch_size = 64):\n",
    "    \n",
    "    \n",
    "    ## It can be seen that the augmentation is applied only on the training set.\n",
    "    ## We have skipped it for val because it is not recommended. But we can try and experiment with it later\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale = 1.0 / 255,\n",
    "                                       rotation_range = 30,\n",
    "                                       width_shift_range = 0.1,\n",
    "                                       height_shift_range = 0.1,\n",
    "                                       zoom_range = 0.1,\n",
    "                                       shear_range = 0.1,\n",
    "                                       fill_mode = \"nearest\"\n",
    "                                      )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                                                            train_dir,\n",
    "                                                            target_size = target_size,\n",
    "                                                            class_mode = 'categorical',\n",
    "                                                            shuffle = True,\n",
    "                                                            batch_size = batch_size\n",
    "                                                        )\n",
    "    \n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "                                                        val_dir,\n",
    "                                                        target_size = target_size,\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = True,\n",
    "                                                        batch_size = batch_size\n",
    "                                                    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                                                        test_dir,\n",
    "                                                        target_size = target_size,\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = False,\n",
    "                                                        batch_size = 1\n",
    "                                                      )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = \"val_acc\",\n",
    "                    min_delta = 0.0001,\n",
    "                    verbose=1,\n",
    "                    patience = 5,\n",
    "                    restore_best_weights = True,\n",
    "                    baseline = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_plot(model, model_name):\n",
    "    train_loss, train_acc, val_loss, val_acc = model.history['loss'], model.history['acc'], model.history['val_loss'], model.history['val_acc']\n",
    "    \n",
    "    plt.plot(train_acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.title('{} Model Accuracy'.format(model_name))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title('{} Model Loss'.format(model_name))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset'        \n",
    "train_dir = 'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/train'\n",
    "val_dir = 'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/val'\n",
    "test_dir = 'SOPM/state-farm-distracted-driver-detection/imgs/cleaned_dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3582 images belonging to 10 classes.\n",
      "Found 444 images belonging to 10 classes.\n",
      "Found 455 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = imagedatageneration(train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(individual):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        # Extract hyperparameters from the individual\n",
    "        feature_extractor_name = individual[0]\n",
    "        hyper = individual[1]\n",
    "        dense_units = individual[2]\n",
    "        dropout_rate = individual[3]\n",
    "        learning_rate = individual[4]\n",
    "        print(feature_extractor_name,hyper,dense_units,dropout_rate ,learning_rate)\n",
    "        # Build the model\n",
    "        if feature_extractor_name == 'VGG19':\n",
    "            base_model = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "        elif feature_extractor_name == 'ResNet50':\n",
    "            base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "        elif feature_extractor_name == 'DenseNet121':\n",
    "            base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False        \n",
    "\n",
    "        last_output = base_model.output\n",
    "        \n",
    "        x = Flatten()(last_output)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(dense_units, activation = hyper)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(dense_units*2, activation = hyper)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "        model = Model(base_model.input, x)\n",
    "        model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_generator, validation_data=val_generator, epochs=15, verbose=1,callbacks = [es])\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_loss,val_accuracy = model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "        return val_accuracy,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_fun(ind):\n",
    "    for i in range(5):\n",
    "            if i==0:\n",
    "                ind[i] = random.choice(['ResNet50','VGG19','DenseNet121'])\n",
    "            elif i==1:\n",
    "                ind[i] = random.choice(['relu','selu','elu'])\n",
    "            elif i==2:\n",
    "                ind[i] = random.randint(64, 256)\n",
    "            elif i==3:\n",
    "                ind[i] = random.uniform(0.2, 0.5)\n",
    "            elif i==4:                \n",
    "                ind[i] = random.uniform(0.0001, 0.01)\n",
    "    return ind,\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\DDM\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "C:\\anaconda\\envs\\DDM\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 elu 103 0.29123736284224033 0.001703472899603407\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 74s 1s/step - loss: 2.3022 - acc: 0.2158 - val_loss: 3.1276 - val_acc: 0.1644\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 42s 740ms/step - loss: 1.9517 - acc: 0.3068 - val_loss: 3.3067 - val_acc: 0.2252\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 43s 768ms/step - loss: 1.8380 - acc: 0.3459 - val_loss: 2.2190 - val_acc: 0.2838\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 43s 763ms/step - loss: 1.7653 - acc: 0.3699 - val_loss: 2.3913 - val_acc: 0.2680\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 45s 808ms/step - loss: 1.7072 - acc: 0.3987 - val_loss: 2.8078 - val_acc: 0.2680\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 46s 822ms/step - loss: 1.6464 - acc: 0.4188 - val_loss: 1.9057 - val_acc: 0.3311\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 1.6157 - acc: 0.4296 - val_loss: 2.3810 - val_acc: 0.2725\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 1.5897 - acc: 0.4344 - val_loss: 1.5286 - val_acc: 0.4527\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 47s 829ms/step - loss: 1.5343 - acc: 0.4629 - val_loss: 1.3905 - val_acc: 0.5045\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 46s 811ms/step - loss: 1.5007 - acc: 0.4732 - val_loss: 1.2208 - val_acc: 0.5991\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 46s 814ms/step - loss: 1.4772 - acc: 0.4813 - val_loss: 1.3001 - val_acc: 0.5495\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 46s 812ms/step - loss: 1.4708 - acc: 0.4841 - val_loss: 1.5468 - val_acc: 0.5270\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 46s 812ms/step - loss: 1.4012 - acc: 0.5047 - val_loss: 1.1742 - val_acc: 0.6104\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 46s 826ms/step - loss: 1.3745 - acc: 0.5215 - val_loss: 1.0520 - val_acc: 0.6689\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 49s 867ms/step - loss: 1.3517 - acc: 0.5254 - val_loss: 1.2792 - val_acc: 0.5631\n",
      "(0.5630630850791931,)\n",
      "VGG19 elu 207 0.2318551800827292 0.0024932048232710244\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 86s 1s/step - loss: 1.5938 - acc: 0.5176 - val_loss: 1.5369 - val_acc: 0.6104\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 49s 874ms/step - loss: 0.6948 - acc: 0.7711 - val_loss: 0.7187 - val_acc: 0.7928\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.5091 - acc: 0.8372 - val_loss: 0.2340 - val_acc: 0.9167\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 49s 876ms/step - loss: 0.3849 - acc: 0.8713 - val_loss: 0.2421 - val_acc: 0.9257\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 900ms/step - loss: 0.3702 - acc: 0.8797 - val_loss: 0.2688 - val_acc: 0.9324\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 50s 881ms/step - loss: 0.3412 - acc: 0.8886 - val_loss: 0.2821 - val_acc: 0.9302\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.3018 - acc: 0.9028 - val_loss: 0.1069 - val_acc: 0.9707\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 49s 874ms/step - loss: 0.2921 - acc: 0.9056 - val_loss: 0.1405 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2404 - acc: 0.9232 - val_loss: 0.1088 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2510 - acc: 0.9157 - val_loss: 0.1527 - val_acc: 0.9662\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 918ms/step - loss: 0.2276 - acc: 0.9207 - val_loss: 0.2012 - val_acc: 0.9527\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 50s 885ms/step - loss: 0.2169 - acc: 0.9260 - val_loss: 0.1176 - val_acc: 0.9752\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.1999 - acc: 0.9322 - val_loss: 0.1215 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 50s 894ms/step - loss: 0.1727 - acc: 0.9417 - val_loss: 0.1349 - val_acc: 0.9662\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 917ms/step - loss: 0.1949 - acc: 0.9341 - val_loss: 0.0940 - val_acc: 0.9842\n",
      "(0.9842342138290405,)\n",
      "VGG19 relu 100 0.22904349576817146 0.002973098849202025\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 915ms/step - loss: 1.4687 - acc: 0.5020 - val_loss: 2.8799 - val_acc: 0.3716\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 50s 893ms/step - loss: 0.6413 - acc: 0.7839 - val_loss: 1.0132 - val_acc: 0.6847\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.4506 - acc: 0.8473 - val_loss: 0.3664 - val_acc: 0.8694\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 51s 912ms/step - loss: 0.3781 - acc: 0.8733 - val_loss: 0.2572 - val_acc: 0.9257\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 908ms/step - loss: 0.3143 - acc: 0.8978 - val_loss: 0.1845 - val_acc: 0.9482\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 50s 887ms/step - loss: 0.3076 - acc: 0.8964 - val_loss: 0.2994 - val_acc: 0.9099\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.2690 - acc: 0.9062 - val_loss: 0.1532 - val_acc: 0.9572\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 50s 890ms/step - loss: 0.2407 - acc: 0.9154 - val_loss: 0.1944 - val_acc: 0.9527\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 906ms/step - loss: 0.2102 - acc: 0.9313 - val_loss: 0.1735 - val_acc: 0.9572\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 902ms/step - loss: 0.1857 - acc: 0.9344 - val_loss: 0.1072 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 50s 898ms/step - loss: 0.1925 - acc: 0.9380 - val_loss: 0.1710 - val_acc: 0.9595\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 51s 906ms/step - loss: 0.1864 - acc: 0.9377 - val_loss: 0.1048 - val_acc: 0.9752\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 50s 891ms/step - loss: 0.1563 - acc: 0.9517 - val_loss: 0.0865 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.1706 - acc: 0.9458 - val_loss: 0.0903 - val_acc: 0.9820\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 911ms/step - loss: 0.1558 - acc: 0.9503 - val_loss: 0.1110 - val_acc: 0.9775\n",
      "(0.977477490901947,)\n",
      "VGG19 relu 224 0.29084738183266284 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 925ms/step - loss: 1.6943 - acc: 0.4779 - val_loss: 16.0392 - val_acc: 0.1464\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.7127 - acc: 0.7624 - val_loss: 3.0422 - val_acc: 0.4977\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 930ms/step - loss: 0.5491 - acc: 0.8180 - val_loss: 2.9287 - val_acc: 0.5698\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.4620 - acc: 0.8465 - val_loss: 0.4598 - val_acc: 0.8784\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.3894 - acc: 0.8666 - val_loss: 0.2205 - val_acc: 0.9527\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 907ms/step - loss: 0.3670 - acc: 0.8780 - val_loss: 0.2717 - val_acc: 0.9347\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.3563 - acc: 0.8791 - val_loss: 0.1622 - val_acc: 0.9707\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 50s 888ms/step - loss: 0.3197 - acc: 0.8908 - val_loss: 0.1751 - val_acc: 0.9482\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 911ms/step - loss: 0.2942 - acc: 0.9009 - val_loss: 0.1973 - val_acc: 0.9527\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 903ms/step - loss: 0.2830 - acc: 0.8981 - val_loss: 0.1317 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2495 - acc: 0.9202 - val_loss: 0.1706 - val_acc: 0.9595\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 50s 898ms/step - loss: 0.2287 - acc: 0.9162 - val_loss: 0.1150 - val_acc: 0.9797\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.1891 - acc: 0.9400 - val_loss: 0.1144 - val_acc: 0.9595\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.2064 - acc: 0.9313 - val_loss: 0.1689 - val_acc: 0.9707\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.1935 - acc: 0.9361 - val_loss: 0.1031 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "DenseNet121 elu 107 0.3775425335949816 0.006090875187832369\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 69s 1s/step - loss: 1.2978 - acc: 0.5650 - val_loss: 0.8522 - val_acc: 0.7162\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 47s 841ms/step - loss: 0.5776 - acc: 0.8049 - val_loss: 0.4886 - val_acc: 0.8581\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 47s 833ms/step - loss: 0.4229 - acc: 0.8565 - val_loss: 0.3889 - val_acc: 0.8851\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 0.3969 - acc: 0.8660 - val_loss: 0.2962 - val_acc: 0.8941\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 0.3103 - acc: 0.8950 - val_loss: 0.2423 - val_acc: 0.9369\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 46s 826ms/step - loss: 0.2923 - acc: 0.9048 - val_loss: 0.1742 - val_acc: 0.9572\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 0.2460 - acc: 0.9190 - val_loss: 0.1504 - val_acc: 0.9617\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 49s 870ms/step - loss: 0.2476 - acc: 0.9196 - val_loss: 0.1218 - val_acc: 0.9707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 48s 862ms/step - loss: 0.2060 - acc: 0.9296 - val_loss: 0.1255 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 0.2167 - acc: 0.9246 - val_loss: 0.1696 - val_acc: 0.9482\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 833ms/step - loss: 0.2116 - acc: 0.9288 - val_loss: 0.1533 - val_acc: 0.9730\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 47s 846ms/step - loss: 0.1995 - acc: 0.9330 - val_loss: 0.1477 - val_acc: 0.9595\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 47s 844ms/step - loss: 0.2136 - acc: 0.9269 - val_loss: 0.1467 - val_acc: 0.9595\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 0.1865 - acc: 0.9372 - val_loss: 0.1507 - val_acc: 0.9550\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 46s 829ms/step - loss: 0.1820 - acc: 0.9439 - val_loss: 0.1437 - val_acc: 0.9617\n",
      "(0.9617117047309875,)\n",
      "ResNet50 elu 223 0.41618983053118186 0.005848400361288513\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 860ms/step - loss: 2.7613 - acc: 0.1806 - val_loss: 9.2526 - val_acc: 0.1284\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 47s 839ms/step - loss: 2.1594 - acc: 0.2448 - val_loss: 3.6596 - val_acc: 0.1824\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 49s 871ms/step - loss: 2.0559 - acc: 0.2850 - val_loss: 2.7663 - val_acc: 0.2072\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 47s 840ms/step - loss: 2.0146 - acc: 0.2990 - val_loss: 2.1451 - val_acc: 0.3266\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 48s 849ms/step - loss: 1.8949 - acc: 0.3345 - val_loss: 1.5990 - val_acc: 0.4257\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 1.8452 - acc: 0.3481 - val_loss: 1.5002 - val_acc: 0.4707\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 48s 849ms/step - loss: 1.8120 - acc: 0.3663 - val_loss: 1.4646 - val_acc: 0.5113\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 47s 836ms/step - loss: 1.7461 - acc: 0.3808 - val_loss: 1.4306 - val_acc: 0.4707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 48s 851ms/step - loss: 1.7216 - acc: 0.3908 - val_loss: 1.5692 - val_acc: 0.4595\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 50s 896ms/step - loss: 1.6510 - acc: 0.4255 - val_loss: 1.3024 - val_acc: 0.5518\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 1.6557 - acc: 0.4151 - val_loss: 1.3318 - val_acc: 0.5203\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 1.6181 - acc: 0.4221 - val_loss: 1.2832 - val_acc: 0.5856\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 1.6109 - acc: 0.4274 - val_loss: 1.1625 - val_acc: 0.6036\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 47s 830ms/step - loss: 1.5541 - acc: 0.4511 - val_loss: 1.1645 - val_acc: 0.6126\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 47s 834ms/step - loss: 1.5350 - acc: 0.4578 - val_loss: 1.1079 - val_acc: 0.6284\n",
      "(0.6283783912658691,)\n",
      "DenseNet121 relu 230 0.22436685646801097 0.009490613854306875\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 54s 864ms/step - loss: 1.7196 - acc: 0.4827 - val_loss: 6.0333 - val_acc: 0.3941\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 47s 836ms/step - loss: 0.7457 - acc: 0.7571 - val_loss: 0.7048 - val_acc: 0.8356\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.5566 - acc: 0.8238 - val_loss: 0.6177 - val_acc: 0.8221\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 46s 822ms/step - loss: 0.3729 - acc: 0.8833 - val_loss: 0.2011 - val_acc: 0.9459\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 48s 850ms/step - loss: 0.3537 - acc: 0.8850 - val_loss: 0.2093 - val_acc: 0.9414\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 47s 831ms/step - loss: 0.3053 - acc: 0.9045 - val_loss: 0.3576 - val_acc: 0.8851\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 47s 841ms/step - loss: 0.2780 - acc: 0.9059 - val_loss: 0.2478 - val_acc: 0.9369\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 0.2224 - acc: 0.9207 - val_loss: 0.1629 - val_acc: 0.9572\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 48s 850ms/step - loss: 0.2162 - acc: 0.9288 - val_loss: 0.2055 - val_acc: 0.9527\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 0.2119 - acc: 0.9296 - val_loss: 0.1929 - val_acc: 0.9505\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 844ms/step - loss: 0.1889 - acc: 0.9361 - val_loss: 0.2048 - val_acc: 0.9527\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 47s 839ms/step - loss: 0.1926 - acc: 0.9347 - val_loss: 0.1435 - val_acc: 0.9640\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 0.1871 - acc: 0.9375 - val_loss: 0.1715 - val_acc: 0.9662\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 0.1787 - acc: 0.9403 - val_loss: 0.1198 - val_acc: 0.9685\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.1612 - acc: 0.9442 - val_loss: 0.1511 - val_acc: 0.9640\n",
      "(0.9639639854431152,)\n",
      "VGG19 elu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 916ms/step - loss: 2.0570 - acc: 0.4204 - val_loss: 3.3077 - val_acc: 0.4887\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 51s 906ms/step - loss: 0.8653 - acc: 0.7088 - val_loss: 0.9375 - val_acc: 0.7770\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.6185 - acc: 0.7948 - val_loss: 0.6720 - val_acc: 0.7838\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 51s 904ms/step - loss: 0.5581 - acc: 0.8244 - val_loss: 0.3504 - val_acc: 0.9099\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.4498 - acc: 0.8523 - val_loss: 0.3380 - val_acc: 0.8986\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 903ms/step - loss: 0.4022 - acc: 0.8638 - val_loss: 0.2608 - val_acc: 0.9324\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.3756 - acc: 0.8797 - val_loss: 0.1830 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 51s 900ms/step - loss: 0.3428 - acc: 0.8883 - val_loss: 0.1622 - val_acc: 0.9505\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.2934 - acc: 0.9031 - val_loss: 0.1433 - val_acc: 0.9572\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 909ms/step - loss: 0.2860 - acc: 0.9076 - val_loss: 0.1479 - val_acc: 0.9572\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.2634 - acc: 0.9118 - val_loss: 0.1826 - val_acc: 0.9527\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.2786 - acc: 0.9090 - val_loss: 0.1954 - val_acc: 0.9482\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2692 - acc: 0.9143 - val_loss: 0.1639 - val_acc: 0.9617\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.2389 - acc: 0.9202 - val_loss: 0.1126 - val_acc: 0.9775\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2394 - acc: 0.9193 - val_loss: 0.0982 - val_acc: 0.9775\n",
      "(0.977477490901947,)\n",
      "DenseNet121 elu 71 0.34488344545262584 0.006308923701951036\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 835ms/step - loss: 1.4401 - acc: 0.5310 - val_loss: 1.6614 - val_acc: 0.5450\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 46s 825ms/step - loss: 0.5668 - acc: 0.8082 - val_loss: 0.4802 - val_acc: 0.8581\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 47s 841ms/step - loss: 0.4557 - acc: 0.8451 - val_loss: 0.2704 - val_acc: 0.9167\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 47s 834ms/step - loss: 0.3508 - acc: 0.8839 - val_loss: 0.2174 - val_acc: 0.9437\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.3043 - acc: 0.8953 - val_loss: 0.2665 - val_acc: 0.9212\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 47s 843ms/step - loss: 0.2788 - acc: 0.9112 - val_loss: 0.2381 - val_acc: 0.9279\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 0.2568 - acc: 0.9112 - val_loss: 0.2692 - val_acc: 0.9302\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 47s 836ms/step - loss: 0.2260 - acc: 0.9288 - val_loss: 0.1729 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 48s 853ms/step - loss: 0.2322 - acc: 0.9157 - val_loss: 0.1996 - val_acc: 0.9482\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 47s 836ms/step - loss: 0.2066 - acc: 0.9327 - val_loss: 0.2607 - val_acc: 0.9392\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 844ms/step - loss: 0.1950 - acc: 0.9338 - val_loss: 0.1934 - val_acc: 0.9595\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 47s 840ms/step - loss: 0.1765 - acc: 0.9414 - val_loss: 0.1487 - val_acc: 0.9662\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 48s 851ms/step - loss: 0.1831 - acc: 0.9366 - val_loss: 0.1757 - val_acc: 0.9640\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 47s 836ms/step - loss: 0.1676 - acc: 0.9417 - val_loss: 0.1312 - val_acc: 0.9775\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 47s 843ms/step - loss: 0.1739 - acc: 0.9436 - val_loss: 0.1229 - val_acc: 0.9730\n",
      "(0.9729729890823364,)\n",
      "VGG19 elu 141 0.34941141804083486 0.008066412726735757\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 914ms/step - loss: 1.7430 - acc: 0.4573 - val_loss: 2.3301 - val_acc: 0.5225\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.7929 - acc: 0.7331 - val_loss: 0.6538 - val_acc: 0.8018\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.6225 - acc: 0.7962 - val_loss: 0.3654 - val_acc: 0.8851\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.4954 - acc: 0.8333 - val_loss: 0.2082 - val_acc: 0.9369\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.4648 - acc: 0.8470 - val_loss: 0.2568 - val_acc: 0.9279\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 909ms/step - loss: 0.4053 - acc: 0.8649 - val_loss: 0.2871 - val_acc: 0.9167\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.3757 - acc: 0.8788 - val_loss: 0.1632 - val_acc: 0.9527\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.3311 - acc: 0.8836 - val_loss: 0.1630 - val_acc: 0.9662\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.3181 - acc: 0.8914 - val_loss: 0.2104 - val_acc: 0.9459\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.3003 - acc: 0.9028 - val_loss: 0.1537 - val_acc: 0.9640\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 949ms/step - loss: 0.2793 - acc: 0.9037 - val_loss: 0.1415 - val_acc: 0.9505\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.2935 - acc: 0.9037 - val_loss: 0.1004 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2661 - acc: 0.9070 - val_loss: 0.1092 - val_acc: 0.9685\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 51s 908ms/step - loss: 0.2653 - acc: 0.9104 - val_loss: 0.1310 - val_acc: 0.9595\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 934ms/step - loss: 0.2523 - acc: 0.9143 - val_loss: 0.1020 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "VGG19 elu 224 0.29084738183266284 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 931ms/step - loss: 1.9036 - acc: 0.4548 - val_loss: 5.9932 - val_acc: 0.3896\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 916ms/step - loss: 0.7622 - acc: 0.7415 - val_loss: 1.0402 - val_acc: 0.7162\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.5866 - acc: 0.7987 - val_loss: 0.2654 - val_acc: 0.9279\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.5197 - acc: 0.8222 - val_loss: 0.2388 - val_acc: 0.9212\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.4408 - acc: 0.8559 - val_loss: 0.1602 - val_acc: 0.9505\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.4032 - acc: 0.8668 - val_loss: 0.1333 - val_acc: 0.9662\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.3507 - acc: 0.8853 - val_loss: 0.1160 - val_acc: 0.9707\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.2908 - acc: 0.8987 - val_loss: 0.1269 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3034 - acc: 0.9009 - val_loss: 0.1404 - val_acc: 0.9550\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2777 - acc: 0.9028 - val_loss: 0.1127 - val_acc: 0.9685\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2789 - acc: 0.9137 - val_loss: 0.1241 - val_acc: 0.9617\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.2732 - acc: 0.9101 - val_loss: 0.1525 - val_acc: 0.9550\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "(0.9707207083702087,)\n",
      "VGG19 relu 248 0.2938144762586819 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 899ms/step - loss: 1.6640 - acc: 0.4955 - val_loss: 8.9667 - val_acc: 0.2523\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.7269 - acc: 0.7588 - val_loss: 3.1016 - val_acc: 0.5428\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.5835 - acc: 0.8107 - val_loss: 1.3057 - val_acc: 0.7725\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.4272 - acc: 0.8562 - val_loss: 0.2365 - val_acc: 0.9032\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 912ms/step - loss: 0.4345 - acc: 0.8546 - val_loss: 0.2326 - val_acc: 0.9414\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.4212 - acc: 0.8652 - val_loss: 0.2060 - val_acc: 0.9482\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.3049 - acc: 0.8998 - val_loss: 0.0981 - val_acc: 0.9662\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2797 - acc: 0.9084 - val_loss: 0.1640 - val_acc: 0.9595\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2801 - acc: 0.9129 - val_loss: 0.1720 - val_acc: 0.9527\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.2800 - acc: 0.9051 - val_loss: 0.1300 - val_acc: 0.9662\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 908ms/step - loss: 0.2401 - acc: 0.9157 - val_loss: 0.1105 - val_acc: 0.9752\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.2324 - acc: 0.9257 - val_loss: 0.1080 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.2355 - acc: 0.9174 - val_loss: 0.0900 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2322 - acc: 0.9243 - val_loss: 0.2803 - val_acc: 0.9279\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 910ms/step - loss: 0.2023 - acc: 0.9330 - val_loss: 0.0907 - val_acc: 0.9820\n",
      "(0.9819819927215576,)\n",
      "ResNet50 relu 160 0.430134271536182 0.009295323467791288\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 49s 826ms/step - loss: 2.6460 - acc: 0.1714 - val_loss: 32.3423 - val_acc: 0.0901\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 49s 868ms/step - loss: 2.1693 - acc: 0.2395 - val_loss: 8.6601 - val_acc: 0.1982\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 48s 847ms/step - loss: 2.0355 - acc: 0.2803 - val_loss: 5.0850 - val_acc: 0.1869\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 48s 851ms/step - loss: 1.9503 - acc: 0.3079 - val_loss: 1.9465 - val_acc: 0.3491\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 1.8652 - acc: 0.3336 - val_loss: 1.4813 - val_acc: 0.4459\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 48s 856ms/step - loss: 1.7992 - acc: 0.3568 - val_loss: 1.4025 - val_acc: 0.4865\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 47s 840ms/step - loss: 1.7602 - acc: 0.3705 - val_loss: 1.5191 - val_acc: 0.4685\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 48s 854ms/step - loss: 1.6850 - acc: 0.4048 - val_loss: 1.6068 - val_acc: 0.4347\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 47s 846ms/step - loss: 1.6685 - acc: 0.4115 - val_loss: 1.3784 - val_acc: 0.5270\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 48s 853ms/step - loss: 1.6436 - acc: 0.4207 - val_loss: 1.2566 - val_acc: 0.5653\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 841ms/step - loss: 1.6022 - acc: 0.4338 - val_loss: 1.3643 - val_acc: 0.5135\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 1.5745 - acc: 0.4411 - val_loss: 1.1590 - val_acc: 0.6081\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 48s 850ms/step - loss: 1.5521 - acc: 0.4528 - val_loss: 1.1235 - val_acc: 0.6149\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 48s 855ms/step - loss: 1.5431 - acc: 0.4551 - val_loss: 1.1262 - val_acc: 0.6329\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 1.5084 - acc: 0.4545 - val_loss: 1.1550 - val_acc: 0.6014\n",
      "(0.6013513803482056,)\n",
      "VGG19 elu 107 0.3775425335949816 0.0024932048232710244\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 888ms/step - loss: 1.5640 - acc: 0.4824 - val_loss: 0.5963 - val_acc: 0.8131\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.7264 - acc: 0.7616 - val_loss: 0.5956 - val_acc: 0.7995\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.5666 - acc: 0.8152 - val_loss: 0.3846 - val_acc: 0.8649\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.5124 - acc: 0.8261 - val_loss: 0.1906 - val_acc: 0.9369\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 910ms/step - loss: 0.4088 - acc: 0.8579 - val_loss: 0.1853 - val_acc: 0.9505\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 917ms/step - loss: 0.3688 - acc: 0.8805 - val_loss: 0.1452 - val_acc: 0.9595\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.3583 - acc: 0.8853 - val_loss: 0.1426 - val_acc: 0.9640\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.3189 - acc: 0.8956 - val_loss: 0.1418 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.3146 - acc: 0.8917 - val_loss: 0.1119 - val_acc: 0.9752\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2749 - acc: 0.9062 - val_loss: 0.1121 - val_acc: 0.9730\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2363 - acc: 0.9252 - val_loss: 0.1001 - val_acc: 0.9820\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2479 - acc: 0.9129 - val_loss: 0.0912 - val_acc: 0.9865\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 50s 898ms/step - loss: 0.2519 - acc: 0.9146 - val_loss: 0.0989 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2563 - acc: 0.9162 - val_loss: 0.1293 - val_acc: 0.9707\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.2442 - acc: 0.9160 - val_loss: 0.1257 - val_acc: 0.9595\n",
      "(0.9594594836235046,)\n",
      "VGG19 elu 207 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 913ms/step - loss: 1.8489 - acc: 0.4662 - val_loss: 3.0857 - val_acc: 0.5045\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.7213 - acc: 0.7594 - val_loss: 1.1301 - val_acc: 0.7297\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 909ms/step - loss: 0.6267 - acc: 0.8004 - val_loss: 0.9495 - val_acc: 0.7950\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.5028 - acc: 0.8336 - val_loss: 0.3248 - val_acc: 0.9279\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4327 - acc: 0.8599 - val_loss: 0.3356 - val_acc: 0.9077\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.3937 - acc: 0.8671 - val_loss: 0.1862 - val_acc: 0.9550\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.3580 - acc: 0.8827 - val_loss: 0.1873 - val_acc: 0.9685\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.3421 - acc: 0.8827 - val_loss: 0.2452 - val_acc: 0.9212\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 917ms/step - loss: 0.2861 - acc: 0.9037 - val_loss: 0.1979 - val_acc: 0.9617\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 907ms/step - loss: 0.2778 - acc: 0.9045 - val_loss: 0.1330 - val_acc: 0.9662\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.2564 - acc: 0.9149 - val_loss: 0.1345 - val_acc: 0.9730\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.2636 - acc: 0.9146 - val_loss: 0.1389 - val_acc: 0.9640\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.2540 - acc: 0.9196 - val_loss: 0.1119 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.2444 - acc: 0.9162 - val_loss: 0.1129 - val_acc: 0.9707\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.2184 - acc: 0.9235 - val_loss: 0.2163 - val_acc: 0.9505\n",
      "(0.9504504799842834,)\n",
      "VGG19 relu 67 0.3011349927347747 0.0020023030156761353\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 903ms/step - loss: 1.6170 - acc: 0.4606 - val_loss: 3.4095 - val_acc: 0.2680\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.7014 - acc: 0.7683 - val_loss: 0.6108 - val_acc: 0.8063\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 904ms/step - loss: 0.4980 - acc: 0.8353 - val_loss: 0.3259 - val_acc: 0.9032\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 51s 917ms/step - loss: 0.3899 - acc: 0.8696 - val_loss: 0.2326 - val_acc: 0.9347\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.3197 - acc: 0.8978 - val_loss: 0.1344 - val_acc: 0.9640\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3266 - acc: 0.8867 - val_loss: 0.2216 - val_acc: 0.9279\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.2733 - acc: 0.9129 - val_loss: 0.1345 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2581 - acc: 0.9118 - val_loss: 0.0970 - val_acc: 0.9820\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2459 - acc: 0.9162 - val_loss: 0.1320 - val_acc: 0.9685\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.2449 - acc: 0.9202 - val_loss: 0.0844 - val_acc: 0.9797\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.2105 - acc: 0.9299 - val_loss: 0.1243 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2144 - acc: 0.9310 - val_loss: 0.1088 - val_acc: 0.9707\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.1942 - acc: 0.9341 - val_loss: 0.0688 - val_acc: 0.9865\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.1871 - acc: 0.9347 - val_loss: 0.0819 - val_acc: 0.9842\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.1670 - acc: 0.9442 - val_loss: 0.0669 - val_acc: 0.9865\n",
      "(0.9864864945411682,)\n",
      "VGG19 elu 248 0.29084738183266284 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 892ms/step - loss: 1.8511 - acc: 0.4576 - val_loss: 2.4939 - val_acc: 0.5856\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 54s 968ms/step - loss: 0.8213 - acc: 0.7418 - val_loss: 0.9664 - val_acc: 0.7545\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.6231 - acc: 0.7937 - val_loss: 0.6097 - val_acc: 0.8536\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.4907 - acc: 0.8414 - val_loss: 0.2070 - val_acc: 0.9505\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.4403 - acc: 0.8559 - val_loss: 0.2501 - val_acc: 0.9302\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.3876 - acc: 0.8752 - val_loss: 0.2201 - val_acc: 0.9550\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.3507 - acc: 0.8841 - val_loss: 0.1989 - val_acc: 0.9302\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3227 - acc: 0.8934 - val_loss: 0.1782 - val_acc: 0.9437\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.3085 - acc: 0.9012 - val_loss: 0.1396 - val_acc: 0.9595\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 934ms/step - loss: 0.2782 - acc: 0.9042 - val_loss: 0.1111 - val_acc: 0.9775\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2822 - acc: 0.9087 - val_loss: 0.1258 - val_acc: 0.9752\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.2660 - acc: 0.9132 - val_loss: 0.1276 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2345 - acc: 0.9210 - val_loss: 0.1158 - val_acc: 0.9640\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 916ms/step - loss: 0.2264 - acc: 0.9255 - val_loss: 0.1445 - val_acc: 0.9640\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.2605 - acc: 0.9143 - val_loss: 0.0800 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "VGG19 relu 224 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 895ms/step - loss: 1.7748 - acc: 0.4609 - val_loss: 11.3913 - val_acc: 0.3288\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.7960 - acc: 0.7415 - val_loss: 2.4827 - val_acc: 0.5991\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.5926 - acc: 0.8009 - val_loss: 1.2597 - val_acc: 0.7252\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.4725 - acc: 0.8501 - val_loss: 0.2497 - val_acc: 0.9347\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.4286 - acc: 0.8573 - val_loss: 0.2815 - val_acc: 0.9257\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3775 - acc: 0.8733 - val_loss: 0.1426 - val_acc: 0.9662\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.3757 - acc: 0.8786 - val_loss: 0.1878 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2815 - acc: 0.9015 - val_loss: 0.1452 - val_acc: 0.9662\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 909ms/step - loss: 0.2883 - acc: 0.9034 - val_loss: 0.1342 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 947ms/step - loss: 0.2597 - acc: 0.9126 - val_loss: 0.1277 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2311 - acc: 0.9249 - val_loss: 0.1537 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 55s 973ms/step - loss: 0.2360 - acc: 0.9210 - val_loss: 0.0890 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 51s 912ms/step - loss: 0.2468 - acc: 0.9213 - val_loss: 0.0806 - val_acc: 0.9842\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2466 - acc: 0.9165 - val_loss: 0.1645 - val_acc: 0.9595\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.2324 - acc: 0.9271 - val_loss: 0.1291 - val_acc: 0.9662\n",
      "(0.9662162065505981,)\n",
      "VGG19 elu 141 0.34941141804083486 0.008066412726735757\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 904ms/step - loss: 1.7466 - acc: 0.4564 - val_loss: 3.8965 - val_acc: 0.3401\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.8092 - acc: 0.7284 - val_loss: 0.6404 - val_acc: 0.8108\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.5927 - acc: 0.8057 - val_loss: 0.5998 - val_acc: 0.8221\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.5059 - acc: 0.8280 - val_loss: 0.3132 - val_acc: 0.9077\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.4893 - acc: 0.8417 - val_loss: 0.2762 - val_acc: 0.9144\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.4373 - acc: 0.8593 - val_loss: 0.2299 - val_acc: 0.9324\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.3656 - acc: 0.8724 - val_loss: 0.2108 - val_acc: 0.9459\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3478 - acc: 0.8814 - val_loss: 0.1374 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.3135 - acc: 0.8936 - val_loss: 0.2581 - val_acc: 0.9347\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.3061 - acc: 0.8984 - val_loss: 0.1952 - val_acc: 0.9482\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2930 - acc: 0.9009 - val_loss: 0.1452 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2748 - acc: 0.9135 - val_loss: 0.0867 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.2637 - acc: 0.9107 - val_loss: 0.2205 - val_acc: 0.9414\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2669 - acc: 0.9070 - val_loss: 0.1176 - val_acc: 0.9775\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2187 - acc: 0.9224 - val_loss: 0.0885 - val_acc: 0.9685\n",
      "(0.9684684872627258,)\n",
      "VGG19 elu 207 0.2318551800827292 0.0024932048232710244\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 895ms/step - loss: 1.4945 - acc: 0.5318 - val_loss: 4.9875 - val_acc: 0.2455\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.7028 - acc: 0.7680 - val_loss: 0.7055 - val_acc: 0.7770\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.4955 - acc: 0.8347 - val_loss: 0.5109 - val_acc: 0.8671\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.4270 - acc: 0.8587 - val_loss: 0.2011 - val_acc: 0.9437\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.3596 - acc: 0.8788 - val_loss: 0.1604 - val_acc: 0.9459\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3301 - acc: 0.8931 - val_loss: 0.3050 - val_acc: 0.9189\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 909ms/step - loss: 0.2913 - acc: 0.9012 - val_loss: 0.2026 - val_acc: 0.9324\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2981 - acc: 0.9017 - val_loss: 0.1634 - val_acc: 0.9572\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 906ms/step - loss: 0.2612 - acc: 0.9135 - val_loss: 0.2042 - val_acc: 0.9392\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.2426 - acc: 0.9190 - val_loss: 0.1729 - val_acc: 0.9617\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2176 - acc: 0.9294 - val_loss: 0.1541 - val_acc: 0.9685\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2243 - acc: 0.9252 - val_loss: 0.2410 - val_acc: 0.9414\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.1790 - acc: 0.9391 - val_loss: 0.0975 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.1962 - acc: 0.9305 - val_loss: 0.1312 - val_acc: 0.9707\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.1721 - acc: 0.9400 - val_loss: 0.1090 - val_acc: 0.9730\n",
      "(0.9729729890823364,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 897ms/step - loss: 1.5538 - acc: 0.4886 - val_loss: 1.4551 - val_acc: 0.5586\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 51s 906ms/step - loss: 0.7510 - acc: 0.7552 - val_loss: 0.8371 - val_acc: 0.7455\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 51s 907ms/step - loss: 0.5784 - acc: 0.8023 - val_loss: 0.2049 - val_acc: 0.9347\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.5023 - acc: 0.8358 - val_loss: 0.2493 - val_acc: 0.9257\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.4316 - acc: 0.8562 - val_loss: 0.2379 - val_acc: 0.9234\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.3980 - acc: 0.8707 - val_loss: 0.1677 - val_acc: 0.9617\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.3849 - acc: 0.8699 - val_loss: 0.1730 - val_acc: 0.9505\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.3334 - acc: 0.8906 - val_loss: 0.1229 - val_acc: 0.9730\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3375 - acc: 0.8864 - val_loss: 0.1086 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2800 - acc: 0.9051 - val_loss: 0.1364 - val_acc: 0.9640\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.3059 - acc: 0.8995 - val_loss: 0.1213 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 951ms/step - loss: 0.2827 - acc: 0.9054 - val_loss: 0.1362 - val_acc: 0.9685\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2533 - acc: 0.9137 - val_loss: 0.0816 - val_acc: 0.9842\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2831 - acc: 0.9079 - val_loss: 0.0825 - val_acc: 0.9842\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.2640 - acc: 0.9115 - val_loss: 0.0964 - val_acc: 0.9820\n",
      "(0.9819819927215576,)\n",
      "VGG19 relu 67 0.3011349927347747 0.0024932048232710244\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 903ms/step - loss: 1.6411 - acc: 0.4417 - val_loss: 4.5487 - val_acc: 0.3581\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.6832 - acc: 0.7786 - val_loss: 1.3327 - val_acc: 0.5586\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.5004 - acc: 0.8378 - val_loss: 0.4734 - val_acc: 0.8446\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 947ms/step - loss: 0.4018 - acc: 0.8615 - val_loss: 0.2088 - val_acc: 0.9279\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.3232 - acc: 0.8942 - val_loss: 0.1678 - val_acc: 0.9437\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.3238 - acc: 0.8939 - val_loss: 0.1355 - val_acc: 0.9617\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2732 - acc: 0.9084 - val_loss: 0.1282 - val_acc: 0.9707\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.2395 - acc: 0.9227 - val_loss: 0.1554 - val_acc: 0.9572\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.2353 - acc: 0.9185 - val_loss: 0.1707 - val_acc: 0.9527\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2171 - acc: 0.9291 - val_loss: 0.1301 - val_acc: 0.9685\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.2047 - acc: 0.9308 - val_loss: 0.1192 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.1968 - acc: 0.9327 - val_loss: 0.0799 - val_acc: 0.9887\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.1833 - acc: 0.9358 - val_loss: 0.0919 - val_acc: 0.9797\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.1871 - acc: 0.9394 - val_loss: 0.1176 - val_acc: 0.9752\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.1680 - acc: 0.9447 - val_loss: 0.1060 - val_acc: 0.9820\n",
      "(0.9819819927215576,)\n",
      "VGG19 relu 224 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 915ms/step - loss: 1.7960 - acc: 0.4584 - val_loss: 13.8683 - val_acc: 0.2905\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.8054 - acc: 0.7334 - val_loss: 4.7104 - val_acc: 0.4347\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.5567 - acc: 0.8138 - val_loss: 0.5425 - val_acc: 0.8311\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.4838 - acc: 0.8417 - val_loss: 0.6087 - val_acc: 0.8266\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.4165 - acc: 0.8587 - val_loss: 0.2563 - val_acc: 0.9369\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.3524 - acc: 0.8850 - val_loss: 0.1315 - val_acc: 0.9685\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.3147 - acc: 0.8987 - val_loss: 0.1578 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3305 - acc: 0.8861 - val_loss: 0.1126 - val_acc: 0.9820\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.2782 - acc: 0.9090 - val_loss: 0.1889 - val_acc: 0.9550\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2592 - acc: 0.9121 - val_loss: 0.1188 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 934ms/step - loss: 0.2603 - acc: 0.9087 - val_loss: 0.1186 - val_acc: 0.9640\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 934ms/step - loss: 0.2751 - acc: 0.9098 - val_loss: 0.2216 - val_acc: 0.9347\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 917ms/step - loss: 0.2315 - acc: 0.9291 - val_loss: 0.1454 - val_acc: 0.9707\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "(0.9819819927215576,)\n",
      "VGG19 relu 248 0.2938144762586819 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 921ms/step - loss: 1.7376 - acc: 0.4760 - val_loss: 16.3025 - val_acc: 0.1509\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.7183 - acc: 0.7641 - val_loss: 1.3991 - val_acc: 0.6982\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.5413 - acc: 0.8216 - val_loss: 0.7151 - val_acc: 0.8198\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.4781 - acc: 0.8448 - val_loss: 0.2066 - val_acc: 0.9324\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.4203 - acc: 0.8571 - val_loss: 0.1781 - val_acc: 0.9392\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.3653 - acc: 0.8769 - val_loss: 0.2047 - val_acc: 0.9527\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 917ms/step - loss: 0.3200 - acc: 0.8867 - val_loss: 0.4884 - val_acc: 0.8694\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 51s 908ms/step - loss: 0.3218 - acc: 0.8897 - val_loss: 0.1532 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2818 - acc: 0.9042 - val_loss: 0.1107 - val_acc: 0.9752\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2626 - acc: 0.9168 - val_loss: 0.1574 - val_acc: 0.9617\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2471 - acc: 0.9165 - val_loss: 0.1122 - val_acc: 0.9685\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2428 - acc: 0.9154 - val_loss: 0.0798 - val_acc: 0.9797\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2318 - acc: 0.9216 - val_loss: 0.1662 - val_acc: 0.9617\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2080 - acc: 0.9322 - val_loss: 0.1098 - val_acc: 0.9685\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2065 - acc: 0.9294 - val_loss: 0.0800 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "ResNet50 relu 175 0.43252161734950617 0.007528440285898631\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 50s 833ms/step - loss: 2.5930 - acc: 0.1739 - val_loss: 17.6466 - val_acc: 0.1396\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 48s 861ms/step - loss: 2.2150 - acc: 0.2406 - val_loss: 7.2193 - val_acc: 0.1532\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 48s 844ms/step - loss: 2.0433 - acc: 0.2864 - val_loss: 4.5688 - val_acc: 0.2005\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 47s 843ms/step - loss: 1.9749 - acc: 0.3088 - val_loss: 2.1042 - val_acc: 0.3311\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 47s 839ms/step - loss: 1.8956 - acc: 0.3328 - val_loss: 1.4590 - val_acc: 0.4887\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 48s 846ms/step - loss: 1.8148 - acc: 0.3518 - val_loss: 1.4019 - val_acc: 0.5135\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 1.7353 - acc: 0.3814 - val_loss: 1.3761 - val_acc: 0.4662\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 48s 853ms/step - loss: 1.7102 - acc: 0.3881 - val_loss: 1.4242 - val_acc: 0.4797\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 47s 841ms/step - loss: 1.6680 - acc: 0.3961 - val_loss: 1.2718 - val_acc: 0.6059\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 48s 847ms/step - loss: 1.6478 - acc: 0.4255 - val_loss: 1.2940 - val_acc: 0.5563\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 47s 829ms/step - loss: 1.5979 - acc: 0.4366 - val_loss: 1.2552 - val_acc: 0.5923\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 48s 855ms/step - loss: 1.5771 - acc: 0.4428 - val_loss: 1.2607 - val_acc: 0.5631\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 47s 840ms/step - loss: 1.5771 - acc: 0.4397 - val_loss: 1.2123 - val_acc: 0.6149\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 48s 850ms/step - loss: 1.5230 - acc: 0.4662 - val_loss: 1.1714 - val_acc: 0.6081\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 47s 843ms/step - loss: 1.5295 - acc: 0.4634 - val_loss: 1.1070 - val_acc: 0.6599\n",
      "(0.6599099040031433,)\n",
      "VGG19 relu 248 0.2938144762586819 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 894ms/step - loss: 1.6567 - acc: 0.4933 - val_loss: 6.5610 - val_acc: 0.5090\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.7245 - acc: 0.7591 - val_loss: 1.5838 - val_acc: 0.6869\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.5632 - acc: 0.8141 - val_loss: 0.6423 - val_acc: 0.8266\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.4119 - acc: 0.8668 - val_loss: 0.7263 - val_acc: 0.8176\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.4157 - acc: 0.8593 - val_loss: 0.3398 - val_acc: 0.9009\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3955 - acc: 0.8674 - val_loss: 0.3449 - val_acc: 0.9122\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.3375 - acc: 0.8867 - val_loss: 0.1660 - val_acc: 0.9572\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 934ms/step - loss: 0.2803 - acc: 0.9095 - val_loss: 0.1180 - val_acc: 0.9707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2508 - acc: 0.9190 - val_loss: 0.1461 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 49s 871ms/step - loss: 0.2806 - acc: 0.9093 - val_loss: 0.1413 - val_acc: 0.9662\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 902ms/step - loss: 0.2736 - acc: 0.9073 - val_loss: 1.0081 - val_acc: 0.7095\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2311 - acc: 0.9238 - val_loss: 0.1606 - val_acc: 0.9572\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 48s 844ms/step - loss: 0.2413 - acc: 0.9235 - val_loss: 0.2309 - val_acc: 0.9459\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "(0.9707207083702087,)\n",
      "VGG19 elu 224 0.29084738183266284 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 51s 884ms/step - loss: 1.7013 - acc: 0.4950 - val_loss: 5.4888 - val_acc: 0.3446\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.7711 - acc: 0.7527 - val_loss: 1.3770 - val_acc: 0.7005\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.5713 - acc: 0.8102 - val_loss: 0.5967 - val_acc: 0.8559\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.4621 - acc: 0.8481 - val_loss: 0.4136 - val_acc: 0.9054\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.3875 - acc: 0.8646 - val_loss: 0.2536 - val_acc: 0.9189\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.3598 - acc: 0.8786 - val_loss: 0.3217 - val_acc: 0.9099\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 914ms/step - loss: 0.3484 - acc: 0.8827 - val_loss: 0.2683 - val_acc: 0.9144\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.3251 - acc: 0.8998 - val_loss: 0.2052 - val_acc: 0.9369\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.2989 - acc: 0.9026 - val_loss: 0.1509 - val_acc: 0.9595\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2847 - acc: 0.9101 - val_loss: 0.1383 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2598 - acc: 0.9149 - val_loss: 0.1249 - val_acc: 0.9752\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 950ms/step - loss: 0.2533 - acc: 0.9149 - val_loss: 0.1345 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2284 - acc: 0.9207 - val_loss: 0.0836 - val_acc: 0.9820\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2161 - acc: 0.9296 - val_loss: 0.1771 - val_acc: 0.9482\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2282 - acc: 0.9243 - val_loss: 0.1734 - val_acc: 0.9595\n",
      "(0.9594594836235046,)\n",
      "VGG19 elu 248 0.29084738183266284 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 910ms/step - loss: 1.9352 - acc: 0.4511 - val_loss: 3.0945 - val_acc: 0.4752\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 54s 965ms/step - loss: 0.8461 - acc: 0.7261 - val_loss: 0.8755 - val_acc: 0.7387\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.6463 - acc: 0.7867 - val_loss: 0.4294 - val_acc: 0.9032\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.4975 - acc: 0.8442 - val_loss: 0.2345 - val_acc: 0.9414\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4186 - acc: 0.8638 - val_loss: 0.1402 - val_acc: 0.9662\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3573 - acc: 0.8766 - val_loss: 0.1586 - val_acc: 0.9662\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.3729 - acc: 0.8741 - val_loss: 0.1340 - val_acc: 0.9730\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3453 - acc: 0.8881 - val_loss: 0.1559 - val_acc: 0.9730\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 48s 852ms/step - loss: 0.3249 - acc: 0.8931 - val_loss: 0.1562 - val_acc: 0.9617\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.2982 - acc: 0.9003 - val_loss: 0.1592 - val_acc: 0.9505\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 51s 912ms/step - loss: 0.2702 - acc: 0.8981 - val_loss: 0.1592 - val_acc: 0.9595\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.2665 - acc: 0.9123 - val_loss: 0.0979 - val_acc: 0.9820\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2434 - acc: 0.9190 - val_loss: 0.1095 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2189 - acc: 0.9319 - val_loss: 0.1169 - val_acc: 0.9685\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 51s 903ms/step - loss: 0.2091 - acc: 0.9336 - val_loss: 0.0996 - val_acc: 0.9730\n",
      "(0.9729729890823364,)\n",
      "VGG19 selu 126 0.24269459847296335 0.00901498541718727\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 906ms/step - loss: 1.6384 - acc: 0.4788 - val_loss: 1.9056 - val_acc: 0.5338\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.7659 - acc: 0.7437 - val_loss: 0.6860 - val_acc: 0.7928\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.5121 - acc: 0.8255 - val_loss: 0.2266 - val_acc: 0.9347\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.4601 - acc: 0.8459 - val_loss: 0.3905 - val_acc: 0.8941\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.4083 - acc: 0.8629 - val_loss: 0.1412 - val_acc: 0.9662\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.3390 - acc: 0.8791 - val_loss: 0.1489 - val_acc: 0.9640\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.2898 - acc: 0.9003 - val_loss: 0.1544 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 951ms/step - loss: 0.3228 - acc: 0.8984 - val_loss: 0.1128 - val_acc: 0.9640\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2523 - acc: 0.9123 - val_loss: 0.1446 - val_acc: 0.9550\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.2402 - acc: 0.9126 - val_loss: 0.1367 - val_acc: 0.9527\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "(0.9662162065505981,)\n",
      "VGG19 elu 248 0.34941141804083486 0.008066412726735757\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 924ms/step - loss: 2.0982 - acc: 0.4104 - val_loss: 3.7373 - val_acc: 0.4685\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.8969 - acc: 0.7021 - val_loss: 2.3297 - val_acc: 0.6081\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.6930 - acc: 0.7741 - val_loss: 1.1280 - val_acc: 0.7545\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.5379 - acc: 0.8224 - val_loss: 0.2840 - val_acc: 0.9122\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 949ms/step - loss: 0.4926 - acc: 0.8428 - val_loss: 0.3447 - val_acc: 0.9077\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.4101 - acc: 0.8635 - val_loss: 0.2516 - val_acc: 0.9234\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 54s 955ms/step - loss: 0.3869 - acc: 0.8719 - val_loss: 0.2146 - val_acc: 0.9572\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3492 - acc: 0.8841 - val_loss: 0.1469 - val_acc: 0.9617\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 54s 954ms/step - loss: 0.3464 - acc: 0.8819 - val_loss: 0.1314 - val_acc: 0.9685\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.3376 - acc: 0.8903 - val_loss: 0.1273 - val_acc: 0.9640\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.2778 - acc: 0.9040 - val_loss: 0.1833 - val_acc: 0.9414\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.2715 - acc: 0.9048 - val_loss: 0.1068 - val_acc: 0.9752\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2676 - acc: 0.9107 - val_loss: 0.2071 - val_acc: 0.9234\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2452 - acc: 0.9179 - val_loss: 0.1498 - val_acc: 0.9482\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 949ms/step - loss: 0.2390 - acc: 0.9171 - val_loss: 0.1093 - val_acc: 0.9707\n",
      "(0.9707207083702087,)\n",
      "ResNet50 relu 222 0.22841037361135413 0.007738736339242276\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 873ms/step - loss: 2.5824 - acc: 0.2032 - val_loss: 35.4124 - val_acc: 0.1374\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 48s 854ms/step - loss: 2.1101 - acc: 0.2887 - val_loss: 15.2230 - val_acc: 0.1149\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 48s 861ms/step - loss: 1.8954 - acc: 0.3442 - val_loss: 5.2617 - val_acc: 0.2928\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 48s 857ms/step - loss: 1.8323 - acc: 0.3529 - val_loss: 2.3122 - val_acc: 0.3626\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 49s 869ms/step - loss: 1.7274 - acc: 0.4056 - val_loss: 1.4031 - val_acc: 0.4955\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 48s 853ms/step - loss: 1.6217 - acc: 0.4333 - val_loss: 1.2938 - val_acc: 0.5495\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 49s 864ms/step - loss: 1.4949 - acc: 0.4791 - val_loss: 1.4099 - val_acc: 0.5450\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 48s 848ms/step - loss: 1.5133 - acc: 0.4671 - val_loss: 1.2404 - val_acc: 0.5653\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 49s 866ms/step - loss: 1.4509 - acc: 0.4989 - val_loss: 1.2962 - val_acc: 0.5721\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 48s 851ms/step - loss: 1.3840 - acc: 0.5109 - val_loss: 1.1356 - val_acc: 0.6239\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 49s 863ms/step - loss: 1.3472 - acc: 0.5260 - val_loss: 1.1318 - val_acc: 0.6104\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 48s 845ms/step - loss: 1.3461 - acc: 0.5296 - val_loss: 31.0240 - val_acc: 0.1734\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 49s 865ms/step - loss: 1.3120 - acc: 0.5444 - val_loss: 1.3702 - val_acc: 0.5788\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 1.2655 - acc: 0.5603 - val_loss: 0.9988 - val_acc: 0.6802\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 49s 863ms/step - loss: 1.2652 - acc: 0.5475 - val_loss: 0.9993 - val_acc: 0.6644\n",
      "(0.6644144058227539,)\n",
      "VGG19 relu 224 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 925ms/step - loss: 1.8211 - acc: 0.4534 - val_loss: 9.2487 - val_acc: 0.3401\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.7701 - acc: 0.7398 - val_loss: 2.5894 - val_acc: 0.5360\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.6056 - acc: 0.7962 - val_loss: 1.4137 - val_acc: 0.7050\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.4866 - acc: 0.8425 - val_loss: 0.2097 - val_acc: 0.9437\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 917ms/step - loss: 0.4042 - acc: 0.8624 - val_loss: 0.2226 - val_acc: 0.9347\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.3724 - acc: 0.8752 - val_loss: 0.3763 - val_acc: 0.9122\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 54s 960ms/step - loss: 0.3944 - acc: 0.8668 - val_loss: 0.2066 - val_acc: 0.9572\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3051 - acc: 0.9031 - val_loss: 0.2164 - val_acc: 0.9414\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.2930 - acc: 0.9034 - val_loss: 0.1311 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2418 - acc: 0.9196 - val_loss: 0.0813 - val_acc: 0.9887\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.2598 - acc: 0.9232 - val_loss: 0.1634 - val_acc: 0.9640\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.2315 - acc: 0.9202 - val_loss: 0.1212 - val_acc: 0.9707\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.2203 - acc: 0.9266 - val_loss: 0.0755 - val_acc: 0.9797\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2188 - acc: 0.9263 - val_loss: 0.0646 - val_acc: 0.9820\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2285 - acc: 0.9193 - val_loss: 0.0763 - val_acc: 0.9820\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "(0.9887387156486511,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 54s 952ms/step - loss: 1.6055 - acc: 0.4743 - val_loss: 1.8141 - val_acc: 0.5721\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.7463 - acc: 0.7535 - val_loss: 0.5934 - val_acc: 0.8041\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.5819 - acc: 0.8035 - val_loss: 0.2247 - val_acc: 0.9234\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.5040 - acc: 0.8342 - val_loss: 0.2393 - val_acc: 0.9302\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.4013 - acc: 0.8702 - val_loss: 0.1765 - val_acc: 0.9459\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.3933 - acc: 0.8668 - val_loss: 0.1984 - val_acc: 0.9459\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.3513 - acc: 0.8816 - val_loss: 0.1538 - val_acc: 0.9640\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3458 - acc: 0.8853 - val_loss: 0.1481 - val_acc: 0.9595\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.3356 - acc: 0.8894 - val_loss: 0.1352 - val_acc: 0.9617\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.3279 - acc: 0.8900 - val_loss: 0.1159 - val_acc: 0.9775\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2986 - acc: 0.9020 - val_loss: 0.1083 - val_acc: 0.9797\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2947 - acc: 0.9062 - val_loss: 0.1243 - val_acc: 0.9640\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 49s 866ms/step - loss: 0.2782 - acc: 0.9082 - val_loss: 0.0932 - val_acc: 0.9820\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 51s 899ms/step - loss: 0.2641 - acc: 0.9087 - val_loss: 0.0947 - val_acc: 0.9752\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.2408 - acc: 0.9146 - val_loss: 0.0861 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 924ms/step - loss: 1.5598 - acc: 0.4858 - val_loss: 1.7973 - val_acc: 0.5968\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 934ms/step - loss: 0.7794 - acc: 0.7351 - val_loss: 0.8980 - val_acc: 0.7568\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.6179 - acc: 0.7937 - val_loss: 0.3547 - val_acc: 0.8919\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4615 - acc: 0.8448 - val_loss: 0.2904 - val_acc: 0.9099\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4160 - acc: 0.8629 - val_loss: 0.2566 - val_acc: 0.9234\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.4122 - acc: 0.8635 - val_loss: 0.3848 - val_acc: 0.8806\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3538 - acc: 0.8791 - val_loss: 0.2081 - val_acc: 0.9369\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 917ms/step - loss: 0.3517 - acc: 0.8850 - val_loss: 0.0815 - val_acc: 0.9842\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3185 - acc: 0.8931 - val_loss: 0.1998 - val_acc: 0.9482\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 54s 964ms/step - loss: 0.3072 - acc: 0.8967 - val_loss: 0.1511 - val_acc: 0.9505\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.3110 - acc: 0.8984 - val_loss: 0.1213 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.2610 - acc: 0.9084 - val_loss: 0.1108 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.2773 - acc: 0.9090 - val_loss: 0.1102 - val_acc: 0.9752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "(0.9842342138290405,)\n",
      "VGG19 relu 224 0.3011349927347747 0.0024932048232710244\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 932ms/step - loss: 1.5336 - acc: 0.5081 - val_loss: 3.1701 - val_acc: 0.4032\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.6398 - acc: 0.7912 - val_loss: 0.8776 - val_acc: 0.7703\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.4990 - acc: 0.8361 - val_loss: 0.3608 - val_acc: 0.9009\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.4217 - acc: 0.8599 - val_loss: 0.1942 - val_acc: 0.9392\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.3472 - acc: 0.8906 - val_loss: 0.1388 - val_acc: 0.9459\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.3299 - acc: 0.8911 - val_loss: 0.1874 - val_acc: 0.9414\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2788 - acc: 0.9101 - val_loss: 0.1373 - val_acc: 0.9640\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2720 - acc: 0.9084 - val_loss: 0.1557 - val_acc: 0.9707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.2514 - acc: 0.9146 - val_loss: 0.1161 - val_acc: 0.9595\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2133 - acc: 0.9266 - val_loss: 0.1272 - val_acc: 0.9730\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2128 - acc: 0.9327 - val_loss: 0.1069 - val_acc: 0.9752\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.2142 - acc: 0.9285 - val_loss: 0.1347 - val_acc: 0.9707\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.1928 - acc: 0.9369 - val_loss: 0.1198 - val_acc: 0.9640\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.1657 - acc: 0.9436 - val_loss: 0.1124 - val_acc: 0.9797\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.1770 - acc: 0.9422 - val_loss: 0.1089 - val_acc: 0.9730\n",
      "(0.9729729890823364,)\n",
      "VGG19 relu 67 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 54s 945ms/step - loss: 1.6095 - acc: 0.4564 - val_loss: 2.1530 - val_acc: 0.4099\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.7342 - acc: 0.7507 - val_loss: 1.4536 - val_acc: 0.5766\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.5254 - acc: 0.8272 - val_loss: 0.3722 - val_acc: 0.8739\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.4463 - acc: 0.8537 - val_loss: 0.2915 - val_acc: 0.8986\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.3797 - acc: 0.8693 - val_loss: 0.2922 - val_acc: 0.9122\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3384 - acc: 0.8819 - val_loss: 0.1727 - val_acc: 0.9595\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.3241 - acc: 0.8928 - val_loss: 0.1265 - val_acc: 0.9752\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.2683 - acc: 0.9073 - val_loss: 0.1505 - val_acc: 0.9685\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.2657 - acc: 0.9079 - val_loss: 0.1412 - val_acc: 0.9730\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.2552 - acc: 0.9132 - val_loss: 0.1305 - val_acc: 0.9707\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2265 - acc: 0.9221 - val_loss: 0.1028 - val_acc: 0.9797\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.2173 - acc: 0.9269 - val_loss: 0.2184 - val_acc: 0.9392\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.2264 - acc: 0.9232 - val_loss: 0.2160 - val_acc: 0.9527\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 919ms/step - loss: 0.2321 - acc: 0.9274 - val_loss: 0.1374 - val_acc: 0.9595\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2056 - acc: 0.9277 - val_loss: 0.0968 - val_acc: 0.9752\n",
      "(0.9752252101898193,)\n",
      "VGG19 elu 93 0.29084738183266284 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 931ms/step - loss: 1.6441 - acc: 0.4578 - val_loss: 2.0364 - val_acc: 0.6014\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.7206 - acc: 0.7546 - val_loss: 0.7140 - val_acc: 0.7995\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.5430 - acc: 0.8146 - val_loss: 0.3765 - val_acc: 0.8941\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.4723 - acc: 0.8512 - val_loss: 0.3604 - val_acc: 0.9032\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3701 - acc: 0.8749 - val_loss: 0.1756 - val_acc: 0.9662\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.3669 - acc: 0.8822 - val_loss: 0.2064 - val_acc: 0.9392\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3353 - acc: 0.8869 - val_loss: 0.1789 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.3431 - acc: 0.8914 - val_loss: 0.1399 - val_acc: 0.9640\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.2562 - acc: 0.9168 - val_loss: 0.1035 - val_acc: 0.9797\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2587 - acc: 0.9104 - val_loss: 0.1204 - val_acc: 0.9797\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.2385 - acc: 0.9207 - val_loss: 0.1579 - val_acc: 0.9527\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.2510 - acc: 0.9157 - val_loss: 0.1017 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 55s 982ms/step - loss: 0.2559 - acc: 0.9218 - val_loss: 0.1326 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 61s 1s/step - loss: 0.2252 - acc: 0.9277 - val_loss: 0.1195 - val_acc: 0.9752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "(0.9797297120094299,)\n",
      "VGG19 selu 248 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 59s 1s/step - loss: 1.8215 - acc: 0.4690 - val_loss: 3.5345 - val_acc: 0.5045\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 54s 963ms/step - loss: 0.8089 - acc: 0.7314 - val_loss: 1.2458 - val_acc: 0.7207\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.6561 - acc: 0.7889 - val_loss: 0.4462 - val_acc: 0.8649\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 54s 963ms/step - loss: 0.5370 - acc: 0.8222 - val_loss: 0.3285 - val_acc: 0.9009\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4994 - acc: 0.8353 - val_loss: 0.5083 - val_acc: 0.8401\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 54s 961ms/step - loss: 0.4419 - acc: 0.8571 - val_loss: 0.2790 - val_acc: 0.9122\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4038 - acc: 0.8682 - val_loss: 0.1895 - val_acc: 0.9482\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 54s 957ms/step - loss: 0.3609 - acc: 0.8811 - val_loss: 0.1373 - val_acc: 0.9707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3688 - acc: 0.8752 - val_loss: 0.2320 - val_acc: 0.9234\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 55s 973ms/step - loss: 0.3318 - acc: 0.8928 - val_loss: 0.1489 - val_acc: 0.9685\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3364 - acc: 0.8839 - val_loss: 0.1825 - val_acc: 0.9392\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.3306 - acc: 0.8959 - val_loss: 0.1311 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.3023 - acc: 0.9026 - val_loss: 0.0948 - val_acc: 0.9707\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3034 - acc: 0.9012 - val_loss: 0.1907 - val_acc: 0.9595\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2552 - acc: 0.9090 - val_loss: 0.1305 - val_acc: 0.9662\n",
      "(0.9662162065505981,)\n",
      "VGG19 relu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 912ms/step - loss: 1.8299 - acc: 0.4542 - val_loss: 20.1028 - val_acc: 0.1532\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 54s 960ms/step - loss: 0.7820 - acc: 0.7398 - val_loss: 2.0947 - val_acc: 0.6351\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.6367 - acc: 0.7931 - val_loss: 0.6332 - val_acc: 0.8401\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 54s 967ms/step - loss: 0.4749 - acc: 0.8428 - val_loss: 0.3076 - val_acc: 0.9189\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.4397 - acc: 0.8518 - val_loss: 0.3863 - val_acc: 0.9077\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3638 - acc: 0.8847 - val_loss: 0.2137 - val_acc: 0.9505\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.3626 - acc: 0.8786 - val_loss: 0.1733 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.3159 - acc: 0.8959 - val_loss: 0.2146 - val_acc: 0.9505\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2557 - acc: 0.9115 - val_loss: 0.1570 - val_acc: 0.9685\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 949ms/step - loss: 0.2687 - acc: 0.9118 - val_loss: 0.1547 - val_acc: 0.9527\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2484 - acc: 0.9179 - val_loss: 0.1540 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.2816 - acc: 0.9048 - val_loss: 0.1404 - val_acc: 0.9685\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.2420 - acc: 0.9174 - val_loss: 0.1213 - val_acc: 0.9752\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.2397 - acc: 0.9216 - val_loss: 0.1447 - val_acc: 0.9685\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2585 - acc: 0.9171 - val_loss: 0.0869 - val_acc: 0.9797\n",
      "(0.9797297120094299,)\n",
      "VGG19 relu 224 0.2938144762586819 0.005381432494706968\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 915ms/step - loss: 1.6868 - acc: 0.4796 - val_loss: 6.1636 - val_acc: 0.5180\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.7332 - acc: 0.7582 - val_loss: 0.9013 - val_acc: 0.7387\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.5287 - acc: 0.8258 - val_loss: 0.7082 - val_acc: 0.7860\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.4587 - acc: 0.8425 - val_loss: 0.2451 - val_acc: 0.9369\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.3713 - acc: 0.8819 - val_loss: 0.1822 - val_acc: 0.9572\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.3757 - acc: 0.8752 - val_loss: 0.1820 - val_acc: 0.9414\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 62s 1s/step - loss: 0.3178 - acc: 0.8948 - val_loss: 0.1693 - val_acc: 0.9662\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 54s 957ms/step - loss: 0.3012 - acc: 0.8998 - val_loss: 0.1397 - val_acc: 0.9595\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.2715 - acc: 0.9109 - val_loss: 0.1194 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.2662 - acc: 0.9115 - val_loss: 0.1889 - val_acc: 0.9595\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2111 - acc: 0.9249 - val_loss: 0.1555 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2211 - acc: 0.9252 - val_loss: 0.1367 - val_acc: 0.9752\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 51s 911ms/step - loss: 0.2320 - acc: 0.9232 - val_loss: 0.0850 - val_acc: 0.9887\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 54s 972ms/step - loss: 0.2145 - acc: 0.9294 - val_loss: 0.1160 - val_acc: 0.9752\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.2236 - acc: 0.9218 - val_loss: 0.0921 - val_acc: 0.9752\n",
      "(0.9752252101898193,)\n",
      "VGG19 relu 224 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 919ms/step - loss: 1.8308 - acc: 0.4514 - val_loss: 14.0650 - val_acc: 0.1644\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.7343 - acc: 0.7510 - val_loss: 4.1143 - val_acc: 0.5360\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.6059 - acc: 0.8049 - val_loss: 1.7842 - val_acc: 0.6599\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.4852 - acc: 0.8375 - val_loss: 0.5217 - val_acc: 0.8671\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4425 - acc: 0.8540 - val_loss: 0.1253 - val_acc: 0.9572\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 920ms/step - loss: 0.3774 - acc: 0.8794 - val_loss: 0.2189 - val_acc: 0.9324\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3191 - acc: 0.8934 - val_loss: 0.1159 - val_acc: 0.9617\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3071 - acc: 0.8981 - val_loss: 0.1408 - val_acc: 0.9527\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.3038 - acc: 0.8981 - val_loss: 0.0976 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2786 - acc: 0.9126 - val_loss: 0.1466 - val_acc: 0.9685\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2515 - acc: 0.9174 - val_loss: 0.1435 - val_acc: 0.9685\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2394 - acc: 0.9143 - val_loss: 0.1647 - val_acc: 0.9685\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2392 - acc: 0.9160 - val_loss: 0.1027 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2189 - acc: 0.9232 - val_loss: 0.1791 - val_acc: 0.9617\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.2165 - acc: 0.9308 - val_loss: 0.3754 - val_acc: 0.9009\n",
      "(0.9009009003639221,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 911ms/step - loss: 1.5797 - acc: 0.4819 - val_loss: 3.2266 - val_acc: 0.4347\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.7362 - acc: 0.7619 - val_loss: 0.4894 - val_acc: 0.8423\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 938ms/step - loss: 0.5784 - acc: 0.8063 - val_loss: 0.8164 - val_acc: 0.7523\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.4854 - acc: 0.8350 - val_loss: 0.2797 - val_acc: 0.9054\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4337 - acc: 0.8557 - val_loss: 0.2189 - val_acc: 0.9369\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4200 - acc: 0.8565 - val_loss: 0.2673 - val_acc: 0.9279\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 54s 954ms/step - loss: 0.3740 - acc: 0.8755 - val_loss: 0.1710 - val_acc: 0.9482\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 934ms/step - loss: 0.3396 - acc: 0.8892 - val_loss: 0.1432 - val_acc: 0.9707\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.3075 - acc: 0.8984 - val_loss: 0.1412 - val_acc: 0.9617\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.3358 - acc: 0.8872 - val_loss: 0.1040 - val_acc: 0.9797\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.2928 - acc: 0.9062 - val_loss: 0.1059 - val_acc: 0.9730\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.2898 - acc: 0.9087 - val_loss: 0.1340 - val_acc: 0.9707\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2524 - acc: 0.9171 - val_loss: 0.1357 - val_acc: 0.9640\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.2786 - acc: 0.9087 - val_loss: 0.1386 - val_acc: 0.9752\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.2504 - acc: 0.9140 - val_loss: 0.1286 - val_acc: 0.9707\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "(0.9797297120094299,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 921ms/step - loss: 1.5623 - acc: 0.4816 - val_loss: 1.7503 - val_acc: 0.5878\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.7439 - acc: 0.7504 - val_loss: 0.7500 - val_acc: 0.8063\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.5783 - acc: 0.8046 - val_loss: 0.3644 - val_acc: 0.8919\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4638 - acc: 0.8389 - val_loss: 0.2985 - val_acc: 0.9009\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.4243 - acc: 0.8629 - val_loss: 0.2600 - val_acc: 0.9189\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.4175 - acc: 0.8554 - val_loss: 0.1852 - val_acc: 0.9482\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.4060 - acc: 0.8654 - val_loss: 0.4833 - val_acc: 0.8604\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 934ms/step - loss: 0.3468 - acc: 0.8808 - val_loss: 0.1826 - val_acc: 0.9459\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.3135 - acc: 0.8900 - val_loss: 0.1687 - val_acc: 0.9685\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 940ms/step - loss: 0.3062 - acc: 0.8961 - val_loss: 0.1375 - val_acc: 0.9752\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.2815 - acc: 0.9042 - val_loss: 0.1027 - val_acc: 0.9842\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2757 - acc: 0.9076 - val_loss: 0.1138 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 951ms/step - loss: 0.2506 - acc: 0.9160 - val_loss: 0.1248 - val_acc: 0.9685\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2616 - acc: 0.9143 - val_loss: 0.1196 - val_acc: 0.9820\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.2692 - acc: 0.9162 - val_loss: 0.1395 - val_acc: 0.9662\n",
      "(0.9662162065505981,)\n",
      "VGG19 elu 93 0.29084738183266284 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 915ms/step - loss: 1.5771 - acc: 0.4774 - val_loss: 2.7383 - val_acc: 0.5090\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.7001 - acc: 0.7641 - val_loss: 0.6317 - val_acc: 0.8176\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 54s 957ms/step - loss: 0.5598 - acc: 0.8102 - val_loss: 0.2535 - val_acc: 0.9144\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.4454 - acc: 0.8504 - val_loss: 0.2317 - val_acc: 0.9212\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 948ms/step - loss: 0.3959 - acc: 0.8660 - val_loss: 0.4162 - val_acc: 0.8739\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.3580 - acc: 0.8800 - val_loss: 0.1961 - val_acc: 0.9302\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.3497 - acc: 0.8825 - val_loss: 0.1476 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.3180 - acc: 0.8945 - val_loss: 0.2029 - val_acc: 0.9459\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2921 - acc: 0.9023 - val_loss: 0.2028 - val_acc: 0.9392\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2623 - acc: 0.9137 - val_loss: 0.1124 - val_acc: 0.9797\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2473 - acc: 0.9174 - val_loss: 0.0942 - val_acc: 0.9797\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.2614 - acc: 0.9176 - val_loss: 0.1714 - val_acc: 0.9505\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.2431 - acc: 0.9179 - val_loss: 0.1036 - val_acc: 0.9775\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.2338 - acc: 0.9199 - val_loss: 0.1077 - val_acc: 0.9775\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2086 - acc: 0.9294 - val_loss: 0.1112 - val_acc: 0.9730\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "(0.9797297120094299,)\n",
      "VGG19 relu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 53s 929ms/step - loss: 1.8202 - acc: 0.4531 - val_loss: 6.7696 - val_acc: 0.4865\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.7995 - acc: 0.7331 - val_loss: 2.0118 - val_acc: 0.6171\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.5805 - acc: 0.8021 - val_loss: 0.7179 - val_acc: 0.8446\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.4794 - acc: 0.8384 - val_loss: 0.4061 - val_acc: 0.8851\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 953ms/step - loss: 0.4176 - acc: 0.8654 - val_loss: 0.2307 - val_acc: 0.9505\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 934ms/step - loss: 0.3724 - acc: 0.8763 - val_loss: 0.2115 - val_acc: 0.9550\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.3639 - acc: 0.8788 - val_loss: 0.1803 - val_acc: 0.9527\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.3095 - acc: 0.8931 - val_loss: 0.0961 - val_acc: 0.9842\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.2620 - acc: 0.9143 - val_loss: 0.1783 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.2698 - acc: 0.9026 - val_loss: 0.1523 - val_acc: 0.9617\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 54s 965ms/step - loss: 0.2716 - acc: 0.9062 - val_loss: 0.1894 - val_acc: 0.9550\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.2287 - acc: 0.9218 - val_loss: 0.1101 - val_acc: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 949ms/step - loss: 0.2443 - acc: 0.9126 - val_loss: 0.1348 - val_acc: 0.9662\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "(0.9842342138290405,)\n",
      "VGG19 relu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 906ms/step - loss: 1.8549 - acc: 0.4475 - val_loss: 14.0138 - val_acc: 0.2365\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.7380 - acc: 0.7454 - val_loss: 3.3935 - val_acc: 0.4955\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.5978 - acc: 0.8065 - val_loss: 5.0474 - val_acc: 0.4459\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.4910 - acc: 0.8381 - val_loss: 0.6318 - val_acc: 0.8221\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.4534 - acc: 0.8487 - val_loss: 0.2731 - val_acc: 0.9212\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3820 - acc: 0.8735 - val_loss: 0.2834 - val_acc: 0.9122\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.3772 - acc: 0.8774 - val_loss: 0.2076 - val_acc: 0.9527\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.2966 - acc: 0.9006 - val_loss: 0.1430 - val_acc: 0.9685\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 54s 954ms/step - loss: 0.2811 - acc: 0.9082 - val_loss: 0.1549 - val_acc: 0.9707\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2594 - acc: 0.9137 - val_loss: 0.1279 - val_acc: 0.9640\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2561 - acc: 0.9135 - val_loss: 0.0826 - val_acc: 0.9820\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2240 - acc: 0.9246 - val_loss: 0.1826 - val_acc: 0.9595\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 935ms/step - loss: 0.2492 - acc: 0.9196 - val_loss: 0.1243 - val_acc: 0.9797\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 934ms/step - loss: 0.2161 - acc: 0.9252 - val_loss: 0.1332 - val_acc: 0.9707\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 53s 950ms/step - loss: 0.2352 - acc: 0.9235 - val_loss: 0.1806 - val_acc: 0.9595\n",
      "(0.9594594836235046,)\n",
      "VGG19 elu 93 0.29084738183266284 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 904ms/step - loss: 1.5904 - acc: 0.4793 - val_loss: 1.8086 - val_acc: 0.5338\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 936ms/step - loss: 0.7163 - acc: 0.7619 - val_loss: 0.4522 - val_acc: 0.8468\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 63s 1s/step - loss: 0.5605 - acc: 0.8155 - val_loss: 0.2912 - val_acc: 0.9167\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 69s 1s/step - loss: 0.4517 - acc: 0.8504 - val_loss: 0.1579 - val_acc: 0.9572\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 70s 1s/step - loss: 0.3998 - acc: 0.8613 - val_loss: 0.2596 - val_acc: 0.9167\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3566 - acc: 0.8844 - val_loss: 0.1468 - val_acc: 0.9482\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 951ms/step - loss: 0.3186 - acc: 0.8867 - val_loss: 0.1222 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.3026 - acc: 0.9001 - val_loss: 0.1783 - val_acc: 0.9482\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 941ms/step - loss: 0.2873 - acc: 0.9068 - val_loss: 0.0954 - val_acc: 0.9730\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.2685 - acc: 0.9109 - val_loss: 0.1498 - val_acc: 0.9640\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.2523 - acc: 0.9179 - val_loss: 0.1437 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.2567 - acc: 0.9104 - val_loss: 0.2081 - val_acc: 0.9482\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 944ms/step - loss: 0.2387 - acc: 0.9224 - val_loss: 0.1153 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.2249 - acc: 0.9249 - val_loss: 0.1032 - val_acc: 0.9662\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "(0.9729729890823364,)\n",
      "VGG19 selu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 54s 947ms/step - loss: 1.6022 - acc: 0.4805 - val_loss: 0.9015 - val_acc: 0.7185\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.7285 - acc: 0.7535 - val_loss: 0.7170 - val_acc: 0.7995\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.6034 - acc: 0.7951 - val_loss: 0.3447 - val_acc: 0.8941\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.4851 - acc: 0.8353 - val_loss: 0.4119 - val_acc: 0.8739\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.4104 - acc: 0.8649 - val_loss: 0.1923 - val_acc: 0.9482\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.4070 - acc: 0.8702 - val_loss: 0.1943 - val_acc: 0.9369\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 51s 910ms/step - loss: 0.3743 - acc: 0.8744 - val_loss: 0.1898 - val_acc: 0.9347\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.3539 - acc: 0.8794 - val_loss: 0.0967 - val_acc: 0.9775\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.3087 - acc: 0.8922 - val_loss: 0.1407 - val_acc: 0.9527\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3374 - acc: 0.8839 - val_loss: 0.1867 - val_acc: 0.9347\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2937 - acc: 0.8984 - val_loss: 0.1235 - val_acc: 0.9595\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.2665 - acc: 0.9082 - val_loss: 0.1104 - val_acc: 0.9617\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 930ms/step - loss: 0.2590 - acc: 0.9146 - val_loss: 0.0990 - val_acc: 0.9775\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "(0.977477490901947,)\n",
      "VGG19 selu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 54s 932ms/step - loss: 1.9261 - acc: 0.4503 - val_loss: 5.0906 - val_acc: 0.3559\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 53s 952ms/step - loss: 0.8171 - acc: 0.7309 - val_loss: 1.4184 - val_acc: 0.6757\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.6554 - acc: 0.7906 - val_loss: 0.3495 - val_acc: 0.9054\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 53s 939ms/step - loss: 0.5890 - acc: 0.8157 - val_loss: 0.3011 - val_acc: 0.9212\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.4470 - acc: 0.8509 - val_loss: 0.1502 - val_acc: 0.9617\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 53s 943ms/step - loss: 0.3832 - acc: 0.8780 - val_loss: 0.2160 - val_acc: 0.9234\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.3844 - acc: 0.8733 - val_loss: 0.1935 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.3211 - acc: 0.8886 - val_loss: 0.2016 - val_acc: 0.9505\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 929ms/step - loss: 0.3117 - acc: 0.8959 - val_loss: 0.2341 - val_acc: 0.9392\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 55s 977ms/step - loss: 0.2709 - acc: 0.9040 - val_loss: 0.1782 - val_acc: 0.9595\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "(0.9617117047309875,)\n",
      "VGG19 relu 93 0.38131872617639273 0.004182888738717628\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 52s 914ms/step - loss: 1.6489 - acc: 0.4461 - val_loss: 4.1262 - val_acc: 0.2928\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 52s 933ms/step - loss: 0.7648 - acc: 0.7398 - val_loss: 2.0692 - val_acc: 0.4685\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 54s 956ms/step - loss: 0.5447 - acc: 0.8166 - val_loss: 0.4014 - val_acc: 0.8649\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 52s 922ms/step - loss: 0.4736 - acc: 0.8425 - val_loss: 0.3847 - val_acc: 0.8468\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 53s 937ms/step - loss: 0.4099 - acc: 0.8582 - val_loss: 0.2473 - val_acc: 0.9144\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 52s 927ms/step - loss: 0.3540 - acc: 0.8844 - val_loss: 0.2134 - val_acc: 0.9324\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 52s 928ms/step - loss: 0.3347 - acc: 0.8816 - val_loss: 0.1609 - val_acc: 0.9414\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2952 - acc: 0.9042 - val_loss: 0.1941 - val_acc: 0.9459\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 52s 932ms/step - loss: 0.2750 - acc: 0.9059 - val_loss: 0.1913 - val_acc: 0.9482\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.3005 - acc: 0.9026 - val_loss: 0.1287 - val_acc: 0.9572\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 53s 946ms/step - loss: 0.2731 - acc: 0.9101 - val_loss: 0.1314 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.2497 - acc: 0.9176 - val_loss: 0.1265 - val_acc: 0.9662\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 52s 925ms/step - loss: 0.2462 - acc: 0.9171 - val_loss: 0.0831 - val_acc: 0.9842\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 918ms/step - loss: 0.2132 - acc: 0.9310 - val_loss: 0.1312 - val_acc: 0.9640\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 52s 935ms/step - loss: 0.2089 - acc: 0.9294 - val_loss: 0.0751 - val_acc: 0.9865\n",
      "(0.9864864945411682,)\n",
      "Best Individual: ['VGG19', 'relu', 248, 0.2938144762586819, 0.007654901613872424] (0.9842342138290405,)\n"
     ]
    }
   ],
   "source": [
    "# Define the genetic algorithm\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "feature_extractors = ['ResNet50','VGG19','DenseNet121']\n",
    "hyperparameter = ['relu','selu','elu']\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_feature_extractor\", lambda: random.choice(feature_extractors))\n",
    "toolbox.register(\"attr_hyper\", lambda: random.choice(hyperparameter))\n",
    "toolbox.register(\"attr_dense_units\", lambda: random.randint(64, 256))\n",
    "toolbox.register(\"attr_dropout_rate\", lambda: random.uniform (0.2, 0.5))\n",
    "toolbox.register(\"attr_learning_rate\", lambda: random.uniform(0.0001, 0.01))\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_feature_extractor,toolbox.attr_hyper, toolbox.attr_dense_units, toolbox.attr_dropout_rate, toolbox.attr_learning_rate), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\",mutation_fun)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "population = toolbox.population(n=10)\n",
    "NGEN = 5\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.2\n",
    "\n",
    "for gen in range(NGEN):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=CXPB, mutpb=MUTPB)\n",
    "    fits = map(toolbox.evaluate, offspring)\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        print(fit)\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    population = toolbox.select(offspring, k=len(population))\n",
    "    \n",
    "\n",
    "\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "print('Best Individual:', best_individual,best_individual.fitness.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19 relu 248 0.2938144762586819 0.007654901613872424\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 44s 769ms/step - loss: 1.8964 - acc: 0.4489 - val_loss: 6.9247 - val_acc: 0.3108\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.7768 - acc: 0.7443 - val_loss: 1.7735 - val_acc: 0.6329\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 50s 883ms/step - loss: 0.5575 - acc: 0.8141 - val_loss: 1.1897 - val_acc: 0.7455\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 56s 990ms/step - loss: 0.4793 - acc: 0.8414 - val_loss: 0.4095 - val_acc: 0.8941\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 62s 1s/step - loss: 0.4297 - acc: 0.8546 - val_loss: 0.3093 - val_acc: 0.9099\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 51s 907ms/step - loss: 0.3770 - acc: 0.8794 - val_loss: 0.3617 - val_acc: 0.8964\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 53s 942ms/step - loss: 0.3397 - acc: 0.8850 - val_loss: 0.1745 - val_acc: 0.9550\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.3133 - acc: 0.9009 - val_loss: 0.1733 - val_acc: 0.9550\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 53s 945ms/step - loss: 0.2696 - acc: 0.9084 - val_loss: 0.1415 - val_acc: 0.9617\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 55s 990ms/step - loss: 0.3155 - acc: 0.8964 - val_loss: 0.1123 - val_acc: 0.9685\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 56s 996ms/step - loss: 0.2765 - acc: 0.9076 - val_loss: 0.1145 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.2427 - acc: 0.9210 - val_loss: 0.0960 - val_acc: 0.9775\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 53s 947ms/step - loss: 0.2281 - acc: 0.9252 - val_loss: 0.1370 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 52s 931ms/step - loss: 0.1981 - acc: 0.9310 - val_loss: 0.1310 - val_acc: 0.9662\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 54s 958ms/step - loss: 0.2123 - acc: 0.9283 - val_loss: 0.1160 - val_acc: 0.9752\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_name = best_individual[0]\n",
    "hyper = best_individual[1]\n",
    "dense_units = best_individual[2]\n",
    "dropout_rate = best_individual[3]\n",
    "learning_rate = best_individual[4]\n",
    "print(feature_extractor_name,hyper,dense_units,dropout_rate ,learning_rate)\n",
    "# Build the model\n",
    "if feature_extractor_name == 'VGG19':\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "elif feature_extractor_name == 'ResNet50':\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "elif feature_extractor_name == 'DenseNet121':\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "    \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False        \n",
    "\n",
    "last_output = base_model.output\n",
    "        \n",
    "x = Flatten()(last_output)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(dense_units, activation = hyper)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(dense_units*2, activation = hyper)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(base_model.input, x)\n",
    "model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=15, verbose=1,callbacks = [es])\n",
    "\n",
    "# Save the model\n",
    "model.save('best_driver_distraction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 7s 13ms/step - loss: 0.1128 - acc: 0.9736\n",
      "Test Accuracy: 0.9736263751983643\n",
      "Confusion Matrix\n",
      "[[48  0  0  0  0  0  0  0  0  3]\n",
      " [ 0 45  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 46  2  0  0  0  0  0]\n",
      " [ 0  0  0  1 46  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  0  0  0  2  0 37  0]\n",
      " [ 1  0  0  0  0  0  0  1  0 41]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          c0       0.98      0.94      0.96        51\n",
      "          c1       1.00      0.98      0.99        46\n",
      "          c2       1.00      1.00      1.00        47\n",
      "          c3       0.96      0.96      0.96        48\n",
      "          c4       0.96      0.98      0.97        47\n",
      "          c5       1.00      0.98      0.99        47\n",
      "          c6       0.94      1.00      0.97        47\n",
      "          c7       0.98      1.00      0.99        40\n",
      "          c8       1.00      0.95      0.97        39\n",
      "          c9       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.97       455\n",
      "   macro avg       0.97      0.97      0.97       455\n",
      "weighted avg       0.97      0.97      0.97       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):    \n",
    "    # Evaluate on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print('Test Accuracy:', test_accuracy)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    Y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(test_generator.classes, y_pred))\n",
    "    \n",
    "    # Classification report\n",
    "    print('Classification Report')\n",
    "    target_names = list(test_generator.class_indices.keys())\n",
    "    print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val_plot(history, best_individual[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
